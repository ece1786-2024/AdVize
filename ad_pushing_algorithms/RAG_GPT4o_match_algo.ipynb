{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install faiss-gpu\n",
        "!pip install openai\n",
        "import torch\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import faiss\n",
        "import openai\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/1786/ECE1786\\ Project/datasets/ad\\ dataset1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkCimzGUueKM",
        "outputId": "5b723994-14b8-4aa9-ebbe-1f2bc164fa96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Mounted at /content/drive\n",
            "/content/drive/.shortcut-targets-by-id/1Xh-uXj6Yy81a9Pk631huGAJzNqGZSA4L/ECE1786 Project/datasets/ad dataset1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_ads_data(file_path):\n",
        "    commercial_ads_data = pd.read_csv(file_path, sep='\\t', on_bad_lines='skip', header=None)\n",
        "\n",
        "    # Remove irrelevant data columns like url, image, user query, etc.\n",
        "    # Only keep the ads title and description\n",
        "    commercial_ads_data = commercial_ads_data.drop(commercial_ads_data.columns[[0, 1, 2, 5, 6, 7, 8, 9]], axis=1)\n",
        "\n",
        "    # Rename columns\n",
        "    commercial_ads_data.columns = ['Ads_Title', 'Ads_Description']\n",
        "\n",
        "    # Combine 'Ads_Title' and 'Ads_Description' into a single 'Ads_Content' column\n",
        "    commercial_ads_data['Ads_Content'] = commercial_ads_data.apply(lambda row: ' | '.join(row.values.astype(str)), axis=1)\n",
        "\n",
        "    # Drop the individual 'Ads_Title' and 'Ads_Description' columns\n",
        "    commercial_ads_data = commercial_ads_data.drop(columns=['Ads_Title', 'Ads_Description'])\n",
        "\n",
        "    return commercial_ads_data\n",
        "\n",
        "ads_data = clean_ads_data('train_250k.tsv')\n",
        "\n",
        "display(ads_data[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "1QEMcUmFubNk",
        "outputId": "4a473289-df8d-4610-af77-54595bac370d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                         Ads_Content\n",
              "0  Klutch 15-Slot Universal Wrench Pouch | Sturdy...\n",
              "1  TAG OFF Skin Natural Skin Tag Remover Take Ski...\n",
              "2  Harley-Davidson Skull LED Fuel Gauge | This lo...\n",
              "3  CHANEL Frt Pocket Handbag Quilted Patent Leath...\n",
              "4  Dell WD15 Monitor Dock 4K with 180W Adapter, U...\n",
              "5  Entwined Halo Diamond Engagement Ring - 14K Ro...\n",
              "6  Emser Tile T06FONT0404UT Trav Fontane Tumbled ...\n",
              "7  Operation Gridlock Caution Sign Adult Unisex H...\n",
              "8  MOEN Kingsley 2-Handle Deck-Mount Roman Tub Tr...\n",
              "9  Stride Rite Cooper 2.0 Lace Boys' Toddler-Yout..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-353de067-4e92-4a2c-97c5-af19301ac4ac\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ads_Content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Klutch 15-Slot Universal Wrench Pouch | Sturdy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TAG OFF Skin Natural Skin Tag Remover Take Ski...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Harley-Davidson Skull LED Fuel Gauge | This lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CHANEL Frt Pocket Handbag Quilted Patent Leath...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dell WD15 Monitor Dock 4K with 180W Adapter, U...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Entwined Halo Diamond Engagement Ring - 14K Ro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Emser Tile T06FONT0404UT Trav Fontane Tumbled ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Operation Gridlock Caution Sign Adult Unisex H...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>MOEN Kingsley 2-Handle Deck-Mount Roman Tub Tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Stride Rite Cooper 2.0 Lace Boys' Toddler-Yout...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-353de067-4e92-4a2c-97c5-af19301ac4ac')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-353de067-4e92-4a2c-97c5-af19301ac4ac button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-353de067-4e92-4a2c-97c5-af19301ac4ac');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6e994b20-bd7d-4263-939b-8d4eec6ce8fc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6e994b20-bd7d-4263-939b-8d4eec6ce8fc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6e994b20-bd7d-4263-939b-8d4eec6ce8fc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(ads_data[:10])\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Ads_Content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"MOEN Kingsley 2-Handle Deck-Mount Roman Tub Trim Kit in Brushed Nickel (Valve Not Included), Grey, Chrome | The Kingsley bath series from MOEN offers a new way for enthusiasts of traditional style to make their bathrooms stand out. By combining classic, antique detailing with modern luxury, Kingsley offers the best of both worlds, delivering an inspired aesthetic to your home. Smoothly finished in brushed nickel, the Kingsley 2-Handle Roman Tub Trim Kit features a dual-lever design, making it easy to control temperature and flow with precision. This trim kit requires MOEN valve 4792, 4793, 4794, 4796, 4797 or 4798 to complete installation. Color: Chrome.\",\n          \"TAG OFF Skin Natural Skin Tag Remover Take Skin Tag Away | Tag OFF \\\"Skin Tag Remover\\\" is a topical remedy made from all-natural plant extracts that help eliminate those harmless skin overgrowths without any pain. Tag Off removes skin tags the all-natural way. Its main ingredients are Thuja occidentalis and Royal Honey. TAGOFF isproven, safe for all types of skin, formulated in the USA. Main benefits are Chemical free, Noscars, painless, fast, Formula 100% Natural, No side effects.\",\n          \"Entwined Halo Diamond Engagement Ring - 14K Rose Gold | Entwined Halo Diamond Engagement Ring - 14K Rose Gold. This dazzling ring features twisted vines of scalloped pav\\u00e9 diamonds leading to a delicately recessed halo around the center gem. Stunning diamond accents flow down the gallery for added brilliance (a\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkZG1qGPrxrQ",
        "outputId": "0c7d075f-8dda-4b55-a1f2-de556111dd84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search Query: Cat-themed phone case for Huawei Pockets2\n",
            "Ad 210144: Camouflage Cat Laptop case | Laptop sleeve. This cat is MADE OF LEAVES! Rhubarb, poplar and pine needle whiskers! Relaxing in his fave garden spot, hes just waiting for his next prey to stroll by cause this mighty hunter is really quite lazy. His camouflage serves him well for this hunting style as he is not seen so well until the last minute. And then we know, at that point, its entirely too late for someone!. Painting & Digital. By TeriMadeLeafArt. cat, cat lovers gift, nature lovers decor, domestic animal, cat in nature, colorful cat, cat t shirt, cat dress, cat pillow, cat clock, orange cat, cat leaves, cat outdoors\n",
            "\n",
            "\n",
            "Search Query: Stylish women's tennis outfits\n",
            "Ad 52929: Nike Women's Pure 11.75 Inch Tennis Skort | The Womens Pure Tennis Skort by Nike features a sleek design that allows you to bring power and finesse to the court The classic Nike looks are updated and improved with the Pure line bringing thicker and softer fabric that flatters all womens bodies The vnotch detail increases range of motion during play The builtin shorts provide coverage and security as well as an option for tennis ball storage DriFIT technology provides sweat management so you stay cool and dry on the court The exclusive recognizable Nike swoosh appears in White on the hem above the left knee\n",
            "\n",
            "\n",
            "Search Query: Affordable noise-cancelling headphones\n",
            "Ad 121589: Sony - WH-CH700N Wireless Noise Cancelling Over-the-Ear Headphones - Black | Add music to your day with these Sony wireless headphones. Their noise cancelling technology uses artificial intelligence to adapt to your environment and reduce background sounds for enjoyable listening. The Quick Charging battery on these over-ear Sony wireless headphones provides up to 35 hours of playback for convenience.\n",
            "\n",
            "\n",
            "Search Query: Fashionable cat-themed jewelry\n",
            "Ad 181834: Bestselling Classic Themed Charm Bracelets | Bestselling Classic Themed Charm Bracelets\n",
            "\n",
            "\n",
            "Search Query: Ergonomic study desk chair\n",
            "Ad 144627: Mid Back Mesh Ergonomic Computer Desk Office Chair, Black | ??EASY TO ASSEMBLE? - The office chair comes with all hardware & necessary tools. Follow the ergonomic chair instruction, you'll found easy to set up, and computer chair estimated assembly time in about 15mins. Office ergonomic computer mesh chair.??COMFORTABLE SEATING? - Thickly cushioned computer chair for maximum comfort. Ergonomic office chair, keep the air circulation in your back, mesh chair perfect addition for you in the office, the study room and the meeting room. Office chair ergonomic chair computer chair mesh chair.??DURABLE & STABLE? - Our ergonomic chair are designed with human-oriented ergonomic construction that lasts long. And the office chair have heavy-duty metal base with 360-degree swivel and nylon smooth-rolling casters, great stability and mobility. Ergonomic chair office chair computer chair mesh chair.??GOOD QUALITY WITH MONEY?- Office chair featuring reliable ergonomic support, mesh chair have breathable mesh back, lumbar support, and generously padded, this ergonomic chair gives you excellent seating experience. Mesh chair office chair computer chair ergonomic chair.??WE ASSURED?- We guarantee you will love this mid-back swivel office chair. But if you?re not satisfied with this mesh chair, please get in touch with us. Ergonomic mesh computer office chair.When selling an office chair, we found that good chair have modern style, beautiful generous and strong practicability especially less money for good quality\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class GPT4OAdMatcher:\n",
        "    def __init__(self, ads_database):\n",
        "        \"\"\"\n",
        "        Initialize the model with an ads database.\n",
        "\n",
        "        :param ads_database: A pandas DataFrame containing ad data with columns ['ad_id', 'ad_text']\n",
        "        \"\"\"\n",
        "        self.ads_database = ads_database\n",
        "        self.vectorizer = TfidfVectorizer(stop_words='english')\n",
        "        self.ads_tfidf_matrix = self.vectorizer.fit_transform(self.ads_database['Ads_Content'])\n",
        "\n",
        "    def find_best_match(self, search_query, top_n=1):\n",
        "        \"\"\"\n",
        "        Given a search query, return the best matched ad from the ads database.\n",
        "\n",
        "        :param search_query: The search query to match.\n",
        "        :param top_n: The number of top matches to return.\n",
        "        :return: A DataFrame containing the best matched ads.\n",
        "        \"\"\"\n",
        "        # Step 1: Use TF-IDF to narrow down candidates\n",
        "        query_tfidf = self.vectorizer.transform([search_query])\n",
        "        cosine_similarities = cosine_similarity(query_tfidf, self.ads_tfidf_matrix).flatten()\n",
        "\n",
        "        # Get the indices of the top_k most similar ads (efficient narrowing down)\n",
        "        top_k = 50  # Adjust top_k as needed for efficiency\n",
        "        top_indices = cosine_similarities.argsort()[-top_k:][::-1]\n",
        "        narrowed_ads = self.ads_database.iloc[top_indices].copy()\n",
        "\n",
        "        return narrowed_ads\n",
        "\n",
        "    def select_best_match_via_gpt4o(self, ads_list, search_query):\n",
        "        \"\"\"\n",
        "        Use GPT-4 API to select the best ad from a list of top matched ads.\n",
        "\n",
        "        :param ads_list: A DataFrame containing the top matched ads.\n",
        "        :return: The best matched ad content as determined by GPT-4.\n",
        "        \"\"\"\n",
        "        # Prepare the prompt for GPT-4\n",
        "        client = openai.OpenAI(api_key=\"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\")\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "            The user's search query is: \"{search_query}\". Based on the given ads, identify the most relevant ad that matches the user's query.\n",
        "            Ads:\n",
        "            \"\"\"\n",
        "        for idx, row in ads_list.iterrows():\n",
        "            prompt += f\"Ad {idx + 1}: {row['Ads_Content']}\"\n",
        "\n",
        "        prompt += \"\"\"\n",
        "        Must return one ad that is the closest match and return the ad content only without any other phases.\n",
        "        \"\"\"\n",
        "\n",
        "        # Call GPT-4 API\n",
        "        response = client.chat.completions.create(\n",
        "                model=\"gpt-4o\",\n",
        "                messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                  {\"role\": \"user\", \"content\": prompt}],\n",
        "                max_tokens=300,\n",
        "                temperature=0.0\n",
        "            )\n",
        "\n",
        "        chosen_ad = response.choices[0].message.content.strip()\n",
        "\n",
        "        return chosen_ad\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    ads_data = ads_data\n",
        "    ads_df = pd.DataFrame(ads_data)\n",
        "\n",
        "    # Initialize the GPT4O ad matcher\n",
        "    ad_matcher = GPT4OAdMatcher(ads_df)\n",
        "\n",
        "    # Define a list of search queries\n",
        "    search_queries = [\n",
        "\n",
        "        \"Cat-themed phone case for Huawei Pockets2\",\n",
        "        \"Stylish women's tennis outfits\",\n",
        "        \"Affordable noise-cancelling headphones\",\n",
        "        \"Fashionable cat-themed jewelry\",\n",
        "        \"Ergonomic study desk chair\"\n",
        "    ]\n",
        "\n",
        "    # Iterate over each search query and find the best matched ad\n",
        "    for search_query in search_queries:\n",
        "        # Find the top matched ads using TF-IDF\n",
        "        top_matched_ads = ad_matcher.find_best_match(search_query)\n",
        "\n",
        "        # Use GPT-4 API to select the best matched ad from the top matches\n",
        "        best_matched_ad = ad_matcher.select_best_match_via_gpt4o(top_matched_ads, search_query)\n",
        "        print(f\"Search Query: {search_query}\")\n",
        "        print(best_matched_ad)\n",
        "        print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "class GPT4OAdMatcher:\n",
        "    def __init__(self, ads_database, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
        "        \"\"\"\n",
        "        Initialize the model with an ads database.\n",
        "\n",
        "        :param ads_database: A pandas DataFrame containing ad data with columns ['ad_id', 'ad_text']\n",
        "        :param model_name: The pre-trained model name from Hugging Face for embedding generation.\n",
        "        \"\"\"\n",
        "        self.ads_database = ads_database\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModel.from_pretrained(model_name)\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        # Generate embeddings for ads\n",
        "        self.ads_embeddings = self._compute_embeddings(self.ads_database['Ads_Content'].tolist())\n",
        "\n",
        "    def _compute_embeddings(self, texts):\n",
        "        \"\"\"\n",
        "        Compute the embeddings for a list of texts.\n",
        "\n",
        "        :param texts: List of texts to compute embeddings for.\n",
        "        :return: A tensor of embeddings.\n",
        "        \"\"\"\n",
        "        inputs = self.tokenizer(texts, padding=True, truncation=True, return_tensors='pt').to(self.device)\n",
        "        with torch.no_grad():\n",
        "            model_output = self.model(**inputs)\n",
        "        embeddings = model_output.last_hidden_state.mean(dim=1)\n",
        "        return embeddings\n",
        "\n",
        "    def find_best_match(self, search_query, top_n=1):\n",
        "        \"\"\"\n",
        "        Given a search query, return the best matched ad from the ads database.\n",
        "\n",
        "        :param search_query: The search query to match.\n",
        "        :param top_n: The number of top matches to return.\n",
        "        :return: A DataFrame containing the best matched ads.\n",
        "        \"\"\"\n",
        "        # Compute the embedding for the search query\n",
        "        query_embedding = self._compute_embeddings([search_query])\n",
        "\n",
        "        # Compute cosine similarities\n",
        "        similarities = torch.nn.functional.cosine_similarity(query_embedding, self.ads_embeddings)\n",
        "        top_indices = torch.topk(similarities, top_n).indices.cpu().numpy()\n",
        "\n",
        "        # Retrieve the top_n ads based on similarity\n",
        "        matched_ads = self.ads_database.iloc[top_indices].copy()\n",
        "        matched_ads['similarity'] = similarities[top_indices].cpu().numpy()\n",
        "\n",
        "        return matched_ads\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Example ads database\n",
        "    ads_data = ads_data\n",
        "    ads_df = pd.DataFrame(ads_data)\n",
        "\n",
        "    # Split ads data into random chunks with max 1000 ads each\n",
        "    ads_chunks = [ads_df.iloc[i:i + 10000] for i in range(0, len(ads_df), 10000)]\n",
        "\n",
        "    # Initialize a list to store top matches from each chunk\n",
        "    top_matches = []\n",
        "\n",
        "    # Define a search query\n",
        "    search_query = \"affordable stylish clothing\"\n",
        "\n",
        "    # Iterate over each chunk and find the top 2 matches\n",
        "    for chunk in ads_chunks:\n",
        "        ad_matcher = GPT4OAdMatcher(chunk)\n",
        "        top_matches_chunk = ad_matcher.find_best_match(search_query, top_n=1)\n",
        "        print(top_matches_chunk)\n",
        "        top_matches.append(top_matches_chunk)\n",
        "\n",
        "    # Combine all top matches into a single DataFrame\n",
        "    combined_top_matches = pd.concat(top_matches, ignore_index=True)\n",
        "\n",
        "    # Use GPT-4 API to select the best matched ad from the combined top matches\n",
        "    ad_matcher = GPT4OAdMatcher(ads_df)\n",
        "    best_matched_ad = ad_matcher.select_best_match_via_gpt4o(combined_top_matches)\n",
        "    print(best_matched_ad)\n",
        "    '''"
      ],
      "metadata": {
        "id": "68iB4LYfGuTq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "26c5a189-61ed-483f-80af-240fcca2b48e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 7.32 GiB. GPU 0 has a total capacity of 14.75 GiB of which 6.41 GiB is free. Process 53821 has 8.33 GiB memory in use. Of the allocated memory 7.70 GiB is allocated by PyTorch, and 518.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7084eaba236e>\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# Iterate over each chunk and find the top 2 matches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mads_chunks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mad_matcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT4OAdMatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mtop_matches_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mad_matcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_best_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_matches_chunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-7084eaba236e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ads_database, model_name)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Generate embeddings for ads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mads_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mads_database\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ads_Content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compute_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-7084eaba236e>\u001b[0m in \u001b[0;36m_compute_embeddings\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1076\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m   1079\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2549\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 7.32 GiB. GPU 0 has a total capacity of 14.75 GiB of which 6.41 GiB is free. Process 53821 has 8.33 GiB memory in use. Of the allocated memory 7.70 GiB is allocated by PyTorch, and 518.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    }
  ]
}
