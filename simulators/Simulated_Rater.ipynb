{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i80Ipo-IjWyE"
      },
      "source": [
        "Initialize Base Search Algo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "k6aLpBgnio89"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/ECE1786\\ Project/datasets/ad\\ dataset1\n",
        "#%cd /content/drive/MyDrive/1786/ECE1786\\ Project/datasets/ad\\ dataset1\n",
        "!pip install gensim transformers torch\n",
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import pandas as pd\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\").to('cuda')\n",
        "def get_bert_embedding(sentence):\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True).to('cuda')\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    embeddings = outputs.last_hidden_state.squeeze(0)\n",
        "    sentence_embedding = embeddings.mean(dim=0)\n",
        "    return sentence_embedding.cpu().numpy()\n",
        "\n",
        "\n",
        "glove_model = api.load(\"glove-wiki-gigaword-300\")\n",
        "def get_glove_embedding(sentence):\n",
        "    words = sentence.lower().split()\n",
        "    word_vectors = [glove_model[word] for word in words if word in glove_model]\n",
        "    if len(word_vectors) == 0:\n",
        "        return np.zeros(300)\n",
        "    sentence_embedding = np.mean(word_vectors, axis=0)\n",
        "    return sentence_embedding\n",
        "\n",
        "\n",
        "file_path = 'train_250k_query_emb.csv'\n",
        "commercial_ads_data = pd.read_csv(file_path, sep=',', on_bad_lines='skip', header = None)\n",
        "commercial_ads_data.columns = commercial_ads_data.iloc[0]\n",
        "commercial_ads_data = commercial_ads_data[1:].reset_index(drop=True)\n",
        "commercial_ads_data = commercial_ads_data.dropna()\n",
        "commercial_ads_data = commercial_ads_data[commercial_ads_data['label'] == '1']\n",
        "\n",
        "\n",
        "glove_weight = 0.7\n",
        "bert_weight = 0.3\n",
        "commercial_ads_data['search_query_bert_embedding'] = commercial_ads_data['search_query_bert_embedding'].apply(\n",
        "    lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \") if isinstance(x, str) else x\n",
        ")\n",
        "commercial_ads_data['query_glove_embedding'] = commercial_ads_data['query_glove_embedding'].apply(\n",
        "    lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \") if isinstance(x, str) else x\n",
        ")\n",
        "commercial_ads_data['query_combined_embedding'] = commercial_ads_data.apply(\n",
        "    lambda row: np.concatenate([\n",
        "        row['query_glove_embedding'] * glove_weight,\n",
        "        row['search_query_bert_embedding'] * bert_weight\n",
        "    ]),\n",
        "    axis=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "E9iDfTuwjF9a"
      },
      "outputs": [],
      "source": [
        "def search_according_to_query(query, commercial_ads_data, glove_weight, bert_weight):\n",
        "\n",
        "  query_embedding = get_glove_embedding(query) * glove_weight\n",
        "  query_embedding_bert = get_bert_embedding(query) * bert_weight\n",
        "  query_combined_embedding = np.concatenate([query_embedding, query_embedding_bert])\n",
        "\n",
        "\n",
        "  #try the concat of them\n",
        "  combined_embeddings = np.vstack(commercial_ads_data['query_combined_embedding'].values)\n",
        "  cos_sim_combined = np.dot(combined_embeddings, query_combined_embedding) / (\n",
        "      np.linalg.norm(combined_embeddings, axis=1) * np.linalg.norm(query_combined_embedding)\n",
        "  )\n",
        "  most_similar_combined_idx = np.argmax(cos_sim_combined)\n",
        "  most_similar_combined_value = cos_sim_combined[most_similar_combined_idx]\n",
        "\n",
        "  most_similar_combined_description = commercial_ads_data.loc[most_similar_combined_idx, 'Ads_Description']\n",
        "  most_similar_combined_query = commercial_ads_data.loc[most_similar_combined_idx, 'Search_Query']\n",
        "  #print(f\"{most_similar_combined_description} \\nMost similar query in database: {most_similar_combined_query} \\n(similarity: {most_similar_combined_value})\")\n",
        "\n",
        "  return most_similar_combined_description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIek-N9nimIX"
      },
      "source": [
        "Simulated Rater"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-HCHNrYJsaTx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qNyfmG40Nbn"
      },
      "outputs": [],
      "source": [
        "# Initialize the OpenAI client\n",
        "# Enzo\n",
        "client = OpenAI(api_key = \"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\")\n",
        "\n",
        "\n",
        "# Load user persona data from a CSV file\n",
        "#file_path = 'user_info.csv'\n",
        "%cd /content/drive/MyDrive/ECE1786\\ Project/\n",
        "\n",
        "file_path = 'user_info.csv'\n",
        "user_data = pd.read_csv(file_path)\n",
        "\n",
        "# Example queries\n",
        "examples = [\n",
        "    \"Portable Wrench Holder\", \"what do skin tags look like on the face\", \"fuel gauges\",\n",
        "    \"horseshoe purse\", \"DELL LAPTOP DOCKING STATION TRIPLE MONITOR\", \"engagement rings\",\n",
        "    \"carpet liquidators\", \"operation gridlock\", \"moen shower faucet repair\", \"3t in sneakers\",\n",
        "    \"concords 11\", \"lifeproof\", \"xbox one +kinect +adapter\", \"roaring 20s women's swimwear\",\n",
        "\n",
        "]\n",
        "\n",
        "# Function to handle both query generation and feedback\n",
        "def generate_query_and_feedback(user_profile, ad_content=None, corr_query=None, examples=examples):\n",
        "    if ad_content:\n",
        "        # Generate a prompt for ad evaluation\n",
        "        prompt = f\"\"\"\n",
        "            You are tasked with evaluating the relevance of an advertisement for a specific query and user profile.\n",
        "\n",
        "            **User Profile**:\n",
        "            - Name: {user_profile['Name']}\n",
        "            - Age: {user_profile['Age']}\n",
        "            - Gender: {user_profile['Gender']}\n",
        "            - Location: {user_profile['Location']}\n",
        "            - Occupation: {user_profile['Occupation']}\n",
        "            - Interests: {\", \".join(user_profile['Interests'])}\n",
        "            - Recent Searches: {\", \".join(user_profile['Search_History'])}\n",
        "\n",
        "            **Query**: {corr_query}\n",
        "\n",
        "            **Ad Content**:\n",
        "            {ad_content}\n",
        "\n",
        "            **Instructions**:\n",
        "            - Respond with:\n",
        "              - Interested: [Yes/No]\n",
        "              - Justification: [A brief explanation of why this ad would or would not interest the user]\n",
        "            - Please notice:\n",
        "              - You need to evaluate the advertisment on both the relevance to the query, but also the interest of the person, if the advertisment is not relevant to the query but is in the interest of the person, it is also considered as interested\n",
        "              - Also, you can inference the race of the person from the name and also consider it as a factor in the evaluation of the advertisment\n",
        "              - Generate the response in the first point of view, for example, use 'I will be interested in this' instead of {user_profile['Name']} is interested in this\n",
        "              - When you making the dicision of interested or not, think in the big picture, think twice on the interests of your persona owner, which are {user_profile['Interests']}, think if the advertisment is aligning with the interest.\n",
        "              - When you making the dicision of interested or not, think generally about the pushed ads don’t get too hung up on the specific items in a particular ad, focus more on the category and features of the ad. For example, if a user searches for RTX4090, if the pushed advertisement is for an older graphics card such as GT260, the user you are playing may also be potentially interested.\n",
        "              - When making the decision of whether an ad is interesting or not, please consider the persona's age and the typical preferences of their age group. Think about how someone in this age group might perceive the ad—would it appeal to their lifestyle, interests, or needs?\n",
        "            **Output**:\n",
        "            - Interested: [Yes/No]\n",
        "            - Justification: [Explanation]\n",
        "        \"\"\"\n",
        "    else:\n",
        "        # Generate a prompt for query generation\n",
        "        prompt = f\"\"\"\n",
        "            You are tasked with generating 10 realistic and contextually appropriate product search queries for a user profile.\n",
        "\n",
        "            **User Profile**:\n",
        "            - Name: {user_profile['Name']}\n",
        "            - Age: {user_profile['Age']}\n",
        "            - Gender: {user_profile['Gender']}\n",
        "            - Location: {user_profile['Location']}\n",
        "            - Occupation: {user_profile['Occupation']}\n",
        "            - Interests: {\", \".join(user_profile['Interests'])}\n",
        "            - Recent Searches: {\", \".join(user_profile['Search_History'])}\n",
        "\n",
        "            **Instructions**:\n",
        "            - Generate 10 realistic and contextually appropriate product search queries for the user profile.\n",
        "              - Reflect on the user's interests, occupation, and recent searches.\n",
        "              - Generate general product search queries relevant to the user’s profile.\n",
        "              - Generated query should be similar to this example: {\", \".join(examples)}.\n",
        "            - Do not include location-specific terms or time-sensitive events in the queries.\n",
        "            - Make sure the generated query is an object that is reasonable and realistic.\n",
        "\n",
        "            **Output**:\n",
        "            - A numbered list of 10 queries. You can only generate this 10 queries, don't output extra words\n",
        "        \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                  {\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.7,\n",
        "        max_tokens=300\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# Interactive simulation\n",
        "print(\"Starting user simulation...\\n\")\n",
        "query_results = []\n",
        "\n",
        "for index, row in user_data.iterrows():\n",
        "    #print(index)\n",
        "    user_profile = {\n",
        "        \"Name\": row['Name'],\n",
        "        \"Age\": row['Age'],\n",
        "        \"Occupation\": row['Occupation'],\n",
        "        \"Location\": row['Location'],\n",
        "        \"Gender\": row['Gender'],\n",
        "        \"Interests\": row['Interests'].split(\", \"),\n",
        "        \"Search_History\": row['Search_History'].split(\", \")\n",
        "    }\n",
        "    print(f\"\\nSimulating user: {user_profile['Name']}\")\n",
        "\n",
        "    # Step 1: Generate queries\n",
        "    print(\"Generating queries and awaiting ad content...\\n\")\n",
        "    queries_and_feedback = generate_query_and_feedback(user_profile)\n",
        "    print(queries_and_feedback)\n",
        "\n",
        "    queries_list = queries_and_feedback.split(\"\\n\")\n",
        "    # Input matched ad details\n",
        "    for query in queries_list:\n",
        "        print('\\n')\n",
        "        #ad_content = input(f\"Enter the ad content for query '{query}': \")\\\n",
        "        ad_content = search_according_to_query(query, commercial_ads_data, glove_weight, bert_weight)\n",
        "\n",
        "        # Step 2: Evaluate ad feedback\n",
        "        print(\"________________\"+ad_content)\n",
        "        feedback = generate_query_and_feedback(user_profile, ad_content=ad_content, corr_query=query)\n",
        "        print(f\"Simulated User Feedback:\\n{feedback}\")\n",
        "\n",
        "\n",
        "        #Process feedback\n",
        "        lines = feedback.split(\"\\n\")\n",
        "        interest_line = [line for line in lines if line.startswith(\"- Interested\")][0]\n",
        "        justification_line = [line for line in lines if line.startswith(\"- Justification\")][0]\n",
        "        interest = 1 if \"Yes\" in interest_line else 0  # Convert Yes to 1, No to 0\n",
        "        justification = justification_line.replace(\"- Justification: \", \"\").strip()\n",
        "\n",
        "        # Save feedback\n",
        "        query_results.append({\n",
        "            \"Name\": user_profile['Name'],\n",
        "            \"Query\": query,\n",
        "            \"Ad_Content\": ad_content,\n",
        "            \"Simulated Feedback\": interest,\n",
        "            \"Simulated Justification\": justification\n",
        "        })\n",
        "\n",
        "    #cont = input(\"Continue to the next user? (yes/no): \").strip().lower()\n",
        "    #if cont != \"yes\":\n",
        "        #break\n",
        "\n",
        "# Save results to a CSV file\n",
        "%cd /content/drive/MyDrive/ECE1786\\ Project/Simulated\\ Feedback\n",
        "feedback_df = pd.DataFrame(query_results)\n",
        "feedback_df.to_csv(\"user_feedback_interactive.csv\", index=False)\n",
        "print(\"\\nFeedback saved to 'user_feedback_interactive.csv'.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}